def conv2d
    "padding" !
    "stride_size" !
    "kernel_size" !
    "out_size" !
    "in_size" !
    
    ; W
    ["out_size" @ "in_size" @ "kernel_size" @ dup ] "YNX_FLOAT" ynx.NewTensor 
    ; B
    ["out_size" @] "YNX_FLOAT" ynx.NewTensor                                      
    
    ; auto_pad, dilation, group, kernel, pads, strides
    "NOTSET" [1 1] 1 ["kernel_size" @ dup] ["padding" @ dup dup dup] ["stride_size" @ dup]             
    onnx.Conv 
end

def max_pool2d
    "NOTSET" 0 [1 1]            ; auto_pad, ceil_Mode, dilation
    [3 3]                       ; kernel_shape
    [0 0 0 0]                   ; pads
    0                           ; storage_order
    [2 2]                       ; strides
    true                        ; we dpnt' want Indices 
    
    onnx.MaxPool
    drop
end

def dropout
    "YNX_FLOAT" ynx.NewScalar
    none none false onnx.Dropout
end

def linear
    "out_size" !
    "in_size" !

    ; W
    ["in_size" @ "out_size" @ ] "YNX_FLOAT" ynx.NewTensor 
    onnx.MatMul

    ; B
    ["out_size" @] "YNX_FLOAT" ynx.NewTensor                                      
    onnx.Add
end

def Features
    3 64 11 4 2 conv2d
    ?? 
    onnx.Relu
    max_pool2d

    64 192 5 1 2 conv2d
    onnx.Relu
    max_pool2d
    
    192 384 3 1 1 conv2d
    onnx.Relu
    384 256 3 1 1 conv2d
    onnx.Relu
    256 256 3 1 1 conv2d
    onnx.Relu
    max_pool2d

    ??
end

def Classifier
    0.5 dropout
    1 onnx.Flatten
    9216 4096 linear
    onnx.Relu

    0.5 dropout
    4096 4096 linear
    onnx.Relu
    
    4096 1000 linear
end


;;
;;  input is batchx3x244x244, output is batchx1000 
;; 
def AlexNet
    Features
    Classifier
end

def test
    [4 3 224 224] "YNX_FLOAT" ynx.NewTensor
    AlexNet
end
